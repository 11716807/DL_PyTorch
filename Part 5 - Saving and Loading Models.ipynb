{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data.\n",
    "\n",
    "First off, I'll implement my own feedforward network for the exercise you worked on in part 4 using the Fashion-MNIST dataset. This will serve as a solution for part 4, as well as an example I'll use to show you how to save and load models.\n",
    "\n",
    "As usually, let's start by loading the dataset through torchvision. You'll learn more about torchvision and loading data in a later part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, it's time to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. I used `nn.ModuleList` to allow for an abritrary number of hidden layers. This model has an argument `hidden_layers` that's a list of the hidden layer sizes (as integers). Using `nn.ModuleList` registers each hidden layer module properly so you can use module methods in the model.\n",
    "\n",
    "I also have the `forward` method returning the log-softmax for the output. Since softmax is a probability distibution over the classes, the log-softmax is a log probability which comes with a [lot of benefits](https://en.wikipedia.org/wiki/Log_probability). Using the log, computations are often faster and more accurate. To get the class probabilities later, I'll need to take the exponential (`torch.exp`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "\n",
    "Since the model's forward method returns the log-softmax, I use the [negative log loss](http://pytorch.org/docs/master/nn.html#nllloss) as my criterion, `nn.NLLLoss()`. I also chose to use the [Adam optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Adam). This is a variant of stochastic gradient descent which includes momentum and in general trains much faster than vanilla SGD.\n",
    "\n",
    "Otherwise, the training code is the same as you've seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "model = Network(784, 10, [500, 100])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2 Loss: 1.7408 Test accuracy: 0.6423\n",
      "Epoch: 1/2 Loss: 0.9796 Test accuracy: 0.6849\n",
      "Epoch: 1/2 Loss: 0.6701 Test accuracy: 0.7298\n",
      "Epoch: 1/2 Loss: 0.6914 Test accuracy: 0.7391\n",
      "Epoch: 1/2 Loss: 0.6576 Test accuracy: 0.7461\n",
      "Epoch: 1/2 Loss: 0.6269 Test accuracy: 0.7435\n",
      "Epoch: 1/2 Loss: 0.6187 Test accuracy: 0.7675\n",
      "Epoch: 1/2 Loss: 0.6374 Test accuracy: 0.7659\n",
      "Epoch: 1/2 Loss: 0.6175 Test accuracy: 0.7680\n",
      "Epoch: 1/2 Loss: 0.5515 Test accuracy: 0.7822\n",
      "Epoch: 1/2 Loss: 0.5092 Test accuracy: 0.7852\n",
      "Epoch: 1/2 Loss: 0.5431 Test accuracy: 0.7983\n",
      "Epoch: 1/2 Loss: 0.5631 Test accuracy: 0.8000\n",
      "Epoch: 1/2 Loss: 0.5246 Test accuracy: 0.7894\n",
      "Epoch: 1/2 Loss: 0.5936 Test accuracy: 0.7846\n",
      "Epoch: 1/2 Loss: 0.6009 Test accuracy: 0.7911\n",
      "Epoch: 1/2 Loss: 0.5236 Test accuracy: 0.8045\n",
      "Epoch: 1/2 Loss: 0.5418 Test accuracy: 0.8025\n",
      "Epoch: 1/2 Loss: 0.5130 Test accuracy: 0.8040\n",
      "Epoch: 1/2 Loss: 0.5019 Test accuracy: 0.8030\n",
      "Epoch: 1/2 Loss: 0.4901 Test accuracy: 0.8016\n",
      "Epoch: 1/2 Loss: 0.5432 Test accuracy: 0.7962\n",
      "Epoch: 1/2 Loss: 0.4918 Test accuracy: 0.8110\n",
      "Epoch: 1/2 Loss: 0.4427 Test accuracy: 0.8056\n",
      "Epoch: 1/2 Loss: 0.5084 Test accuracy: 0.8065\n",
      "Epoch: 1/2 Loss: 0.4938 Test accuracy: 0.8081\n",
      "Epoch: 1/2 Loss: 0.5598 Test accuracy: 0.7954\n",
      "Epoch: 1/2 Loss: 0.4948 Test accuracy: 0.7985\n",
      "Epoch: 1/2 Loss: 0.5069 Test accuracy: 0.8184\n",
      "Epoch: 1/2 Loss: 0.4514 Test accuracy: 0.8235\n",
      "Epoch: 1/2 Loss: 0.4459 Test accuracy: 0.8233\n",
      "Epoch: 1/2 Loss: 0.4745 Test accuracy: 0.8209\n",
      "Epoch: 1/2 Loss: 0.5032 Test accuracy: 0.8179\n",
      "Epoch: 1/2 Loss: 0.4613 Test accuracy: 0.8192\n",
      "Epoch: 1/2 Loss: 0.4735 Test accuracy: 0.8017\n",
      "Epoch: 1/2 Loss: 0.3859 Test accuracy: 0.8074\n",
      "Epoch: 1/2 Loss: 0.4938 Test accuracy: 0.8134\n",
      "Epoch: 1/2 Loss: 0.4718 Test accuracy: 0.8278\n",
      "Epoch: 1/2 Loss: 0.4462 Test accuracy: 0.8333\n",
      "Epoch: 1/2 Loss: 0.4382 Test accuracy: 0.8285\n",
      "Epoch: 1/2 Loss: 0.4449 Test accuracy: 0.8254\n",
      "Epoch: 1/2 Loss: 0.5047 Test accuracy: 0.8349\n",
      "Epoch: 1/2 Loss: 0.4391 Test accuracy: 0.8297\n",
      "Epoch: 1/2 Loss: 0.4564 Test accuracy: 0.8254\n",
      "Epoch: 1/2 Loss: 0.4622 Test accuracy: 0.8342\n",
      "Epoch: 1/2 Loss: 0.3937 Test accuracy: 0.8350\n",
      "Epoch: 1/2 Loss: 0.3866 Test accuracy: 0.8364\n",
      "Epoch: 1/2 Loss: 0.4087 Test accuracy: 0.8279\n",
      "Epoch: 1/2 Loss: 0.4405 Test accuracy: 0.8290\n",
      "Epoch: 1/2 Loss: 0.4180 Test accuracy: 0.8255\n",
      "Epoch: 1/2 Loss: 0.4691 Test accuracy: 0.8348\n",
      "Epoch: 1/2 Loss: 0.4911 Test accuracy: 0.8373\n",
      "Epoch: 1/2 Loss: 0.4961 Test accuracy: 0.8346\n",
      "Epoch: 1/2 Loss: 0.4283 Test accuracy: 0.8386\n",
      "Epoch: 1/2 Loss: 0.3873 Test accuracy: 0.8358\n",
      "Epoch: 1/2 Loss: 0.4217 Test accuracy: 0.8361\n",
      "Epoch: 1/2 Loss: 0.4060 Test accuracy: 0.8366\n",
      "Epoch: 1/2 Loss: 0.4484 Test accuracy: 0.8289\n",
      "Epoch: 1/2 Loss: 0.4179 Test accuracy: 0.8313\n",
      "Epoch: 1/2 Loss: 0.4034 Test accuracy: 0.8314\n",
      "Epoch: 1/2 Loss: 0.3957 Test accuracy: 0.8382\n",
      "Epoch: 1/2 Loss: 0.5627 Test accuracy: 0.8374\n",
      "Epoch: 1/2 Loss: 0.4236 Test accuracy: 0.8372\n",
      "Epoch: 1/2 Loss: 0.3821 Test accuracy: 0.8346\n",
      "Epoch: 1/2 Loss: 0.3527 Test accuracy: 0.8414\n",
      "Epoch: 1/2 Loss: 0.4283 Test accuracy: 0.8353\n",
      "Epoch: 1/2 Loss: 0.4190 Test accuracy: 0.8327\n",
      "Epoch: 1/2 Loss: 0.4527 Test accuracy: 0.8295\n",
      "Epoch: 1/2 Loss: 0.4251 Test accuracy: 0.8414\n",
      "Epoch: 1/2 Loss: 0.4166 Test accuracy: 0.8386\n",
      "Epoch: 1/2 Loss: 0.3598 Test accuracy: 0.8436\n",
      "Epoch: 1/2 Loss: 0.3637 Test accuracy: 0.8392\n",
      "Epoch: 1/2 Loss: 0.4512 Test accuracy: 0.8303\n",
      "Epoch: 1/2 Loss: 0.4372 Test accuracy: 0.8489\n",
      "Epoch: 1/2 Loss: 0.4421 Test accuracy: 0.8429\n",
      "Epoch: 1/2 Loss: 0.4726 Test accuracy: 0.8387\n",
      "Epoch: 1/2 Loss: 0.4125 Test accuracy: 0.8413\n",
      "Epoch: 1/2 Loss: 0.4200 Test accuracy: 0.8422\n",
      "Epoch: 1/2 Loss: 0.3930 Test accuracy: 0.8420\n",
      "Epoch: 1/2 Loss: 0.3784 Test accuracy: 0.8473\n",
      "Epoch: 1/2 Loss: 0.4675 Test accuracy: 0.8462\n",
      "Epoch: 1/2 Loss: 0.4209 Test accuracy: 0.8410\n",
      "Epoch: 1/2 Loss: 0.4241 Test accuracy: 0.8384\n",
      "Epoch: 1/2 Loss: 0.4020 Test accuracy: 0.8319\n",
      "Epoch: 1/2 Loss: 0.4138 Test accuracy: 0.8453\n",
      "Epoch: 1/2 Loss: 0.3917 Test accuracy: 0.8281\n",
      "Epoch: 1/2 Loss: 0.3492 Test accuracy: 0.8397\n",
      "Epoch: 1/2 Loss: 0.3396 Test accuracy: 0.8526\n",
      "Epoch: 1/2 Loss: 0.4395 Test accuracy: 0.8445\n",
      "Epoch: 1/2 Loss: 0.3411 Test accuracy: 0.8373\n",
      "Epoch: 1/2 Loss: 0.4051 Test accuracy: 0.8385\n",
      "Epoch: 1/2 Loss: 0.4281 Test accuracy: 0.8433\n",
      "Epoch: 1/2 Loss: 0.3541 Test accuracy: 0.8527\n",
      "Epoch: 2/2 Loss: 0.3630 Test accuracy: 0.8378\n",
      "Epoch: 2/2 Loss: 0.4558 Test accuracy: 0.8390\n",
      "Epoch: 2/2 Loss: 0.3761 Test accuracy: 0.8581\n",
      "Epoch: 2/2 Loss: 0.3741 Test accuracy: 0.8525\n",
      "Epoch: 2/2 Loss: 0.4108 Test accuracy: 0.8488\n",
      "Epoch: 2/2 Loss: 0.3393 Test accuracy: 0.8430\n",
      "Epoch: 2/2 Loss: 0.4027 Test accuracy: 0.8448\n",
      "Epoch: 2/2 Loss: 0.3804 Test accuracy: 0.8561\n",
      "Epoch: 2/2 Loss: 0.3815 Test accuracy: 0.8339\n",
      "Epoch: 2/2 Loss: 0.3904 Test accuracy: 0.8556\n",
      "Epoch: 2/2 Loss: 0.3618 Test accuracy: 0.8473\n",
      "Epoch: 2/2 Loss: 0.3183 Test accuracy: 0.8344\n",
      "Epoch: 2/2 Loss: 0.3596 Test accuracy: 0.8464\n",
      "Epoch: 2/2 Loss: 0.3940 Test accuracy: 0.8505\n",
      "Epoch: 2/2 Loss: 0.3427 Test accuracy: 0.8432\n",
      "Epoch: 2/2 Loss: 0.3895 Test accuracy: 0.8419\n",
      "Epoch: 2/2 Loss: 0.3672 Test accuracy: 0.8489\n",
      "Epoch: 2/2 Loss: 0.3518 Test accuracy: 0.8477\n",
      "Epoch: 2/2 Loss: 0.3465 Test accuracy: 0.8491\n",
      "Epoch: 2/2 Loss: 0.3837 Test accuracy: 0.8550\n",
      "Epoch: 2/2 Loss: 0.3884 Test accuracy: 0.8381\n",
      "Epoch: 2/2 Loss: 0.4394 Test accuracy: 0.8374\n",
      "Epoch: 2/2 Loss: 0.3960 Test accuracy: 0.8447\n",
      "Epoch: 2/2 Loss: 0.3254 Test accuracy: 0.8530\n",
      "Epoch: 2/2 Loss: 0.3414 Test accuracy: 0.8489\n",
      "Epoch: 2/2 Loss: 0.3644 Test accuracy: 0.8548\n",
      "Epoch: 2/2 Loss: 0.4045 Test accuracy: 0.8489\n",
      "Epoch: 2/2 Loss: 0.3680 Test accuracy: 0.8468\n",
      "Epoch: 2/2 Loss: 0.3162 Test accuracy: 0.8601\n",
      "Epoch: 2/2 Loss: 0.3409 Test accuracy: 0.8649\n",
      "Epoch: 2/2 Loss: 0.3471 Test accuracy: 0.8615\n",
      "Epoch: 2/2 Loss: 0.3920 Test accuracy: 0.8396\n",
      "Epoch: 2/2 Loss: 0.4031 Test accuracy: 0.8156\n",
      "Epoch: 2/2 Loss: 0.3860 Test accuracy: 0.8488\n",
      "Epoch: 2/2 Loss: 0.3480 Test accuracy: 0.8533\n",
      "Epoch: 2/2 Loss: 0.3885 Test accuracy: 0.8525\n",
      "Epoch: 2/2 Loss: 0.3723 Test accuracy: 0.8476\n",
      "Epoch: 2/2 Loss: 0.3621 Test accuracy: 0.8616\n",
      "Epoch: 2/2 Loss: 0.3262 Test accuracy: 0.8555\n",
      "Epoch: 2/2 Loss: 0.3861 Test accuracy: 0.8512\n",
      "Epoch: 2/2 Loss: 0.3974 Test accuracy: 0.8511\n",
      "Epoch: 2/2 Loss: 0.4169 Test accuracy: 0.8523\n",
      "Epoch: 2/2 Loss: 0.3313 Test accuracy: 0.8588\n",
      "Epoch: 2/2 Loss: 0.3356 Test accuracy: 0.8597\n",
      "Epoch: 2/2 Loss: 0.3957 Test accuracy: 0.8573\n",
      "Epoch: 2/2 Loss: 0.3652 Test accuracy: 0.8598\n",
      "Epoch: 2/2 Loss: 0.3644 Test accuracy: 0.8513\n",
      "Epoch: 2/2 Loss: 0.3379 Test accuracy: 0.8622\n",
      "Epoch: 2/2 Loss: 0.3312 Test accuracy: 0.8602\n",
      "Epoch: 2/2 Loss: 0.3290 Test accuracy: 0.8598\n",
      "Epoch: 2/2 Loss: 0.3692 Test accuracy: 0.8588\n",
      "Epoch: 2/2 Loss: 0.3420 Test accuracy: 0.8585\n",
      "Epoch: 2/2 Loss: 0.3304 Test accuracy: 0.8508\n",
      "Epoch: 2/2 Loss: 0.3827 Test accuracy: 0.8533\n",
      "Epoch: 2/2 Loss: 0.3978 Test accuracy: 0.8573\n",
      "Epoch: 2/2 Loss: 0.3562 Test accuracy: 0.8515\n",
      "Epoch: 2/2 Loss: 0.3981 Test accuracy: 0.8534\n",
      "Epoch: 2/2 Loss: 0.3586 Test accuracy: 0.8475\n",
      "Epoch: 2/2 Loss: 0.4081 Test accuracy: 0.8475\n",
      "Epoch: 2/2 Loss: 0.3880 Test accuracy: 0.8591\n",
      "Epoch: 2/2 Loss: 0.3825 Test accuracy: 0.8653\n",
      "Epoch: 2/2 Loss: 0.3467 Test accuracy: 0.8608\n",
      "Epoch: 2/2 Loss: 0.3831 Test accuracy: 0.8565\n",
      "Epoch: 2/2 Loss: 0.2984 Test accuracy: 0.8529\n",
      "Epoch: 2/2 Loss: 0.3363 Test accuracy: 0.8528\n",
      "Epoch: 2/2 Loss: 0.3914 Test accuracy: 0.8581\n",
      "Epoch: 2/2 Loss: 0.3377 Test accuracy: 0.8522\n",
      "Epoch: 2/2 Loss: 0.3446 Test accuracy: 0.8600\n",
      "Epoch: 2/2 Loss: 0.3449 Test accuracy: 0.8582\n",
      "Epoch: 2/2 Loss: 0.3805 Test accuracy: 0.8552\n",
      "Epoch: 2/2 Loss: 0.4026 Test accuracy: 0.8639\n",
      "Epoch: 2/2 Loss: 0.3479 Test accuracy: 0.8611\n",
      "Epoch: 2/2 Loss: 0.3495 Test accuracy: 0.8539\n",
      "Epoch: 2/2 Loss: 0.3878 Test accuracy: 0.8587\n",
      "Epoch: 2/2 Loss: 0.3010 Test accuracy: 0.8519\n",
      "Epoch: 2/2 Loss: 0.3283 Test accuracy: 0.8581\n",
      "Epoch: 2/2 Loss: 0.3694 Test accuracy: 0.8592\n",
      "Epoch: 2/2 Loss: 0.3830 Test accuracy: 0.8441\n",
      "Epoch: 2/2 Loss: 0.4065 Test accuracy: 0.8585\n",
      "Epoch: 2/2 Loss: 0.3743 Test accuracy: 0.8620\n",
      "Epoch: 2/2 Loss: 0.3444 Test accuracy: 0.8612\n",
      "Epoch: 2/2 Loss: 0.3437 Test accuracy: 0.8584\n",
      "Epoch: 2/2 Loss: 0.3572 Test accuracy: 0.8601\n",
      "Epoch: 2/2 Loss: 0.3782 Test accuracy: 0.8675\n",
      "Epoch: 2/2 Loss: 0.3320 Test accuracy: 0.8634\n",
      "Epoch: 2/2 Loss: 0.3529 Test accuracy: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/2 Loss: 0.3904 Test accuracy: 0.8672\n",
      "Epoch: 2/2 Loss: 0.3896 Test accuracy: 0.8614\n",
      "Epoch: 2/2 Loss: 0.3597 Test accuracy: 0.8544\n",
      "Epoch: 2/2 Loss: 0.3459 Test accuracy: 0.8638\n",
      "Epoch: 2/2 Loss: 0.3430 Test accuracy: 0.8632\n",
      "Epoch: 2/2 Loss: 0.3599 Test accuracy: 0.8543\n",
      "Epoch: 2/2 Loss: 0.3562 Test accuracy: 0.8617\n",
      "Epoch: 2/2 Loss: 0.3281 Test accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "for e in range(epochs):\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Flatten images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # Wrap images and labels in Variables so we can calculate gradients\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(testloader):\n",
    "                \n",
    "                images = images.resize_(images.size()[0], 784)\n",
    "                inputs = Variable(images, volatile=True)\n",
    "                \n",
    "                predicted = torch.exp(model.forward(inputs).data)\n",
    "                equality = (labels == predicted.max(1)[1])\n",
    "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "            \n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}\".format(accuracy/(ii+1)))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks\n",
    "\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our network: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500)\n",
      "    (1): Linear(in_features=500, out_features=100)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the state dick with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "While copying the parameter named hidden_layers.0.weight, whose dimensions in the model are torch.Size([400, 784]) and whose dimensions in the checkpoint are torch.Size([500, 784]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [400 x 784] and src [500 x 784] to have the same number of elements, but got 313600 and 392000 elements respectively at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512381214802/work/torch/lib/TH/generic/THTensorCopy.c:86",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-74e14cc8e983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named hidden_layers.0.weight, whose dimensions in the model are torch.Size([400, 784]) and whose dimensions in the checkpoint are torch.Size([500, 784])."
     ]
    }
   ],
   "source": [
    "# Try this\n",
    "net = Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the checkpoint has all the necessary information to rebuild the trained model. You can easily make that a function if you want. Similarly, we can write a function to load checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network(checkpoint['input_size'],\n",
    "                    checkpoint['output_size'],\n",
    "                    checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500)\n",
      "    (1): Linear(in_features=500, out_features=100)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
